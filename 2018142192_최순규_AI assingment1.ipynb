{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "5ydlTMIPwyS4"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8cHqEAbSwyij"
   },
   "source": [
    "## Assignment 1-1\n",
    "동영상 데이터에 대한 Linear classifier를 구현해보세요\n",
    "\n",
    "- Input data : 32 x 32 size, RGB channel, 100 frame\n",
    "- the number of samples : 500\n",
    "\n",
    "**Input data, weights, bias, score 가 출력될 수 있도록 구현해주세요**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "N4NH1kKzwyWG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[233 230 202 ... 152 224  68]\n",
      " [ 66 196 145 ...  96 204 241]\n",
      " [230   9  49 ...  18 103 106]\n",
      " ...\n",
      " [145  16 240 ... 104 216 199]\n",
      " [ 11  22  64 ... 230 131 251]\n",
      " [214 193 116 ... 152  93  55]] <--x\n",
      "x shape is:  (307200, 500) \n",
      "\n",
      "[[-1.15755387e-02  3.20072332e-02 -6.78983688e-03 ...  4.00390480e-04\n",
      "  -2.05691602e-03  2.35614265e-03]\n",
      " [ 6.42528581e-03  3.28768693e-04 -4.68737505e-03 ...  1.98721238e-02\n",
      "   2.19012525e-03 -2.38510022e-02]\n",
      " [ 1.04923384e-02 -1.19159042e-02 -5.87290221e-04 ... -4.11282505e-05\n",
      "  -1.08319419e-02 -3.63793866e-03]\n",
      " ...\n",
      " [ 3.95282305e-03  3.08597392e-03 -2.13694344e-02 ... -8.79922695e-04\n",
      "  -6.91056679e-03  9.02700524e-03]\n",
      " [ 3.86654640e-03  1.44439544e-02  1.00666027e-02 ...  1.72935399e-02\n",
      "  -1.46592120e-02  1.61388494e-03]\n",
      " [ 8.71701998e-04 -9.23996049e-03 -3.71513134e-03 ... -5.33041576e-03\n",
      "  -5.18342506e-04 -4.21675474e-03]] <--W\n",
      "W shape is:  (10, 307200) \n",
      "\n",
      "[[ 0.20762155  0.99028056 -0.44289771 ... -0.16252416 -0.56664207\n",
      "  -0.9642863 ]\n",
      " [-0.60120532  0.32803999  0.82813963 ...  0.77355346 -1.00030155\n",
      "  -0.91589872]\n",
      " [-1.18336879 -0.85600402  0.59309006 ...  0.10970656 -0.73030727\n",
      "   2.13975866]\n",
      " ...\n",
      " [ 1.12700942 -0.30250125  1.23100804 ... -0.98748786 -0.61249434\n",
      "  -0.49858702]\n",
      " [-0.31393504 -0.30717913  0.14080036 ... -0.93763432 -1.91646308\n",
      "  -1.1997339 ]\n",
      " [ 0.02204434  1.12312082 -0.35203935 ... -0.16682991  0.82788081\n",
      "   0.72254036]] <--b\n",
      "b shape is:  (10, 500) \n",
      "\n",
      "[[   89.86836841    61.70328899  -852.65796541 ...  -797.13663535\n",
      "   -186.65183046  -376.70755905]\n",
      " [ -200.74630743  -134.70679155  1000.04151519 ...    84.78960702\n",
      "   -130.69569734   702.99213393]\n",
      " [  458.49613565  -131.67195224   368.28379709 ...   664.26981851\n",
      "   -534.7505063   -894.06883126]\n",
      " ...\n",
      " [  883.66534352   453.44482112  1014.82093453 ...  -267.71066943\n",
      "    475.09039463     8.11108649]\n",
      " [ -228.16265217  -536.05255587  -109.18861227 ...  -257.25309778\n",
      "   -594.67577542    10.80489005]\n",
      " [-1413.97843392 -1285.37634534 -2211.52381268 ... -1960.12107087\n",
      "  -1699.13521142 -1259.48614182]] <--s\n",
      "s shape is:  (10, 500)\n"
     ]
    }
   ],
   "source": [
    "# Assignment 1-1 구현은 여기서\n",
    "vid_shape=[100,32,32,3] #이미지와 다르게 새로 추가된 차원인 프레임 값을 맨 앞에 넣음\n",
    "\n",
    "num_class=10 #임의로 10개로 정함\n",
    "num_sample=500 #주어진 값\n",
    "data_shape=[100,32,32,3,num_sample] #비디오의 각 차원 + 샘플값까지 고려해 data_shape을 설정\n",
    "\n",
    "vid_size=vid_shape[0]*vid_shape[1]*vid_shape[2]*vid_shape[3] #비디오의 각 차원을 곱해 사이즈 측정\n",
    "\n",
    "x_data=np.random.randint(255,size=data_shape) #임의로 정한 비디오 데이터는 이런 형식을 띰\n",
    "x=np.reshape(x_data, (-1,num_sample)) # input data를 size 307200 x 500으로 reshape해줌\n",
    "W=np.random.normal(0,0.01,size=(num_class, vid_size)) #Weights (size 10 x 307200)\n",
    "b=np.random.normal(0,1,size=(num_class, num_sample)) #bias (size 10 x 500)\n",
    "\n",
    "s=np.dot(W,x)+b # score (size 10 x 500)\n",
    "\n",
    "#데이터 사이즈에 맞게 W,x,b를 설정해 score값을 구하도록 하였음.\n",
    "#x,W,b,s모두 직관적으로 보이지 않아서 배열 자체와 배열의 shape를 함께 출력하였음.\n",
    "print(x,'<--x')\n",
    "print('x shape is: ', x.shape, '\\n')\n",
    "\n",
    "print(W,'<--W')\n",
    "print('W shape is: ', W.shape, '\\n')\n",
    "\n",
    "print(b, '<--b')\n",
    "print('b shape is: ', b.shape, '\\n')\n",
    "\n",
    "print(s, '<--s')\n",
    "print('s shape is: ', s.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dcpZnrdYwwTe"
   },
   "source": [
    "##Assignment 1-2\n",
    "\n",
    "1) L2 Regularization을 구현해보세요 (아래 Loss_reg 함수 참조)\n",
    "\n",
    "- 코드만 구현하면 됩니다\n",
    "\n",
    "\n",
    "2) 주어진 MNIST dataset을 이용하여 SVM loss와 Regularization loss를 구해보세요\n",
    "\n",
    "- SVM loss와 L1, L2 Regularization loss를 모두 출력해 주세요\n",
    "\n",
    "3) Total loss 구해보세요 (lambda = 0.1)\n",
    "\n",
    "- lambda값을 0.1로 설정하여 total loss를 모두 출력해주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "0Fvjs18bzE61"
   },
   "outputs": [],
   "source": [
    "# SVM Loss \n",
    "\n",
    "def Loss_SVM(s, y):\n",
    "    delta = 1.0\n",
    "    [num_class, num_sample] = s.shape\n",
    "    Li = 0\n",
    "    for i in range(num_sample):\n",
    "        ysample = y[:,i]\n",
    "        ssample = s[:,i]\n",
    "        ysample_index = np.where(ysample==1)[0][0]\n",
    "        for j in range(num_class):\n",
    "            if j == ysample_index:\n",
    "                continue\n",
    "            else:\n",
    "                Li += max(0, ssample[j] - ssample[ysample_index] + delta)\n",
    "    return Li/num_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "CUUWkSp1yoMB"
   },
   "outputs": [],
   "source": [
    "# mnist data load\n",
    "\n",
    "mnist = sklearn.datasets.fetch_openml('mnist_784', data_home=\"mnist_784\")\n",
    "\n",
    "num_sample = 5000\n",
    "num_class = 10\n",
    "\n",
    "x = mnist.data[:num_sample]\n",
    "img_size = x[0].size\n",
    "y_index = mnist.target[:num_sample]\n",
    "\n",
    "y = np.zeros((num_class, num_sample))\n",
    "for idx in range(num_sample):\n",
    "    y[int(y_index[idx]), idx] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "id": "uQt-dvUax0kZ"
   },
   "outputs": [],
   "source": [
    "# 1) Loss reg 구현은 여기서\n",
    "\n",
    "def Loss_reg(W, dim=2):\n",
    "    if dim == 1: # L1 regularization:\n",
    "        reg = np.sum(abs(W))\n",
    "    elif dim == 2:\n",
    "        reg = np.sum(W**2) #L2는 W의 값들을 제곱해서 구현함.\n",
    "\n",
    "    return reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "id": "5xanQJJox-G-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape is : (5000, 784)\n",
      "W shape is : (10, 784)\n",
      "b shape is : (10, 5000)\n",
      "s shape is : (10, 5000)\n"
     ]
    }
   ],
   "source": [
    "# 2) MNIST linear classifer 구현은 여기서\n",
    "W=np.random.normal(0,0.002,size=(num_class, img_size))\n",
    "#적절한 W를 찾을 수 있으면 좋겠지만 적당히 작은 수준에서 랜덤변수를 활용해 Weight값을 임의로 지정\n",
    "b=np.random.normal(0,1,size=(num_class,num_sample)) #랜덤변수를 활용하고 Wx와 동일한 size를 가진 b형성\n",
    "\n",
    "s=np.dot(W,x.T)+b\n",
    "\"\"\"주어진 x데이터는 각 샘플이 가로축이고 그것이 5000개 쌓여있는 모양임. 이것은 우리가 기존에 구한\n",
    "score나 y배열과는 다른 모양이므로 x.T로 dot product를 수행해서 배열의 모양을 맞춰줌.\"\"\"\n",
    "\n",
    "print('x shape is :', x.shape)\n",
    "print('W shape is :', W.shape)\n",
    "print('b shape is :', b.shape)\n",
    "print('s shape is :', s.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "id": "uWLiXJpHyE0_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total loss L1:  34.716314590253\n",
      "total loss L2:  33.45511176146328\n",
      "svm loss:  33.45190696460981\n"
     ]
    }
   ],
   "source": [
    "# 3) Total Loss 구현은 여기서\n",
    "loss=Loss_SVM(s,y) #SVM_Loss\n",
    "reg_term_L1 = Loss_reg(W, dim=1) #L1\n",
    "reg_term_L2 = Loss_reg(W, dim=2) #L2\n",
    "print('total loss L1: ', loss+0.1*reg_term_L1) #L1 regularization을 사용\n",
    "print('total loss L2: ', loss+0.1*reg_term_L2) #L2 regularization을 사용\n",
    "#sainity check를 제대로 통과하는 것을 확인했다.\n",
    "#주어진 값대로 하이퍼파라미터의 값을 0.1로 설정하였다.\n",
    "print('svm loss: ', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment1",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
